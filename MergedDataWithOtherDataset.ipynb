{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def str_to_datetime(datelist,ymd_type):\n",
    "    datelist = datelist.dropna()\n",
    "    for i,dat in enumerate(datelist):\n",
    "        datelist[i] = datetime.strptime(dat, ymd_type)\n",
    "    return datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display all the columns\n",
    "pd.options.display.max_columns = 120\n",
    "pd.options.display.max_rows = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movies_after2014_IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data for Yiran&Yuxin --- twitter date data \n",
    "#Select +-3 days time window\n",
    "df.release_date = str_to_datetime(df.release_date,'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "import datetime\n",
    "df['start_date'] = df.release_date - datetime.timedelta(days = 3)\n",
    "df['end_date'] = df.release_date + datetime.timedelta(days = 3)\n",
    "\n",
    "df.release_date\n",
    "\n",
    "df2 = df[['original_title','start_date','end_date']]\n",
    "\n",
    "df2.to_csv('movielist_S2E.csv')\n",
    "\n",
    "df3 = pd.read_csv('movielist_S2E.csv')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuwe\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Reading the dataset from IMDB website --- many dataset\n",
    "name_basics = pd.read_csv('imdb/name_basics.tsv',sep='\\t')\n",
    "title_ratings = pd.read_csv('imdb/title_ratings.tsv',sep='\\t')\n",
    "title_episode = pd.read_csv('imdb/title_episode.tsv',sep='\\t')\n",
    "title_crews = pd.read_csv('imdb/title_crew.tsv',sep='\\t')\n",
    "title_basics = pd.read_csv('imdb/title_basics.tsv',sep='\\t')\n",
    "title_akas = pd.read_csv('imdb/title_akas.tsv',sep='\\t')\n",
    "\n",
    "print(name_basics.columns)\n",
    "print(title_ratings.columns)\n",
    "print(title_episode.columns)\n",
    "print(title_crews.columns)\n",
    "print(title_basics.columns)\n",
    "print(title_akas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.merge(title_basics,df,'right',left_on='primaryTitle',right_on='title')\n",
    "df4 = df3[df3['titleType']=='movie']\n",
    "len(df3['primaryTitle'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuwe\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Merge the dataset after 2014 with the metadata dataset --- right join containing Nan\n",
    "metadata = pd.read_csv('movie_metadata.csv')\n",
    "\n",
    "for i,mov in enumerate(metadata.movie_title):\n",
    "    metadata.movie_title[i] = mov.replace(u'\\xa0', u'')\n",
    "\n",
    "merged_data = pd.merge(metadata,df,'right',left_on='movie_title',right_on='title')\n",
    "\n",
    "merged_data = pd.read_csv('merged_IMDB_and_metadata.csv')\n",
    "merged_data\n",
    "\n",
    "temp = merged_data.title.value_counts() > 1\n",
    "duplicate_list = temp[temp == True].index\n",
    "\n",
    "\n",
    "for i,name in enumerate(duplicate_list):\n",
    "    temp = merged_data[merged_data['title']== name].iloc[-1:]\n",
    "    merged_data = merged_data[merged_data['title'] != name]\n",
    "    merged_data = pd.concat([merged_data,temp])\n",
    "\n",
    "\n",
    "\n",
    "merged_data = merged_data.drop(columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1'])\n",
    "\n",
    "merged_data.to_csv('merged_IMDB_and_metadata.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Delete missing value\n",
    "merged_data_noNan = merged_data[merged_data['movie_title'].isnull().values == False]\n",
    "merged_data_noNan.to_csv('merged_data_innerJoin.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
